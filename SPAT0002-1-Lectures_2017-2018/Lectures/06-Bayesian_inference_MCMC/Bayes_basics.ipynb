{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian inference: Basics\n",
    "\n",
    "## Table of Content:\n",
    "\n",
    "- I [Frequentist vs Bayesian inference](#I.-Frequentist-vs-Bayesian-Approaches)\n",
    "- II [The Bayesian Problem Setting](#II.-The-Bayesian-Problem-Setting)\n",
    "- III [The Bayes' theorem / Bayes' Rule](#III-The-Bayes'-theorem-/-Bayes'-Rule):\n",
    "- IV Simple Bayesian Modeling: See [Bayes_simple_modeling.ipynb](Bayes_simple_modeling.ipynb)\n",
    "- V Bayesian modeling with Monte Carlo Markov Chains (MCMC): See [Bayes_MCMC.ipynb](Bayes_MCMC.ipynb)\n",
    "- XX [Referemces](#XX-References:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Frequentist vs Bayesian Approaches\n",
    "\n",
    "Both the model fitting and model selection problems can be approached from either a *frequentist* or a *Bayesian* standpoint.\n",
    "Fundamentally, the difference between these lies in the **definition of probability** that they use:\n",
    "\n",
    "- **A frequentist probability is a measure *long-run frequency* of (real or imagined) repeated trials.** Among other things, this generally means that observed data can be described probabilistically (you can repeat the experiment and get a different realization) while model parameters are fixed, and cannot be described probabilistically (the universe remains the same no matter how many times you observe it). \n",
    "\n",
    "- **A Bayesian probability is a *quantification of belief*.** Among other things, this generally means that observed data are treated as fixed (you know exactly what values you measured) while model parameters – including the \"true\" values of the data reflected by noisy measurements – are treated probabilistically (your degree of knowledge about the universe changes as you gather more data).\n",
    "\n",
    "\n",
    "**Example**: The measurement of the flux of a star.\n",
    "\n",
    "- For frequentists, **probability** only has meaning in terms of a **limiting case of repeated measurements**. That is, if I measure the photon flux F from a given star (we'll assume for now that the star's flux does not vary with time), then measure it again, then again, and so on, each time I will get a slightly different answer due to the statistical error of my measuring device. In the limit of a large number of measurements, the frequency of any given value indicates the probability of measuring that value. For frequentists probabilities are fundamentally related to **frequencies of events**. This means, for example, that in a strict frequentist view, it is *meaningless* to talk about the probability of the true flux of the star: the true flux is (by definition) a single fixed value, and to talk about a frequency distribution for a fixed value is nonsense.\n",
    "\n",
    "- For Bayesians, the concept of probability is extended to cover degrees of certainty about statements. Say a Bayesian claims to measure the flux F of a star with some probability P(F): that probability can certainly be estimated from frequencies in the limit of a large number of repeated experiments, but this is not fundamental. The probability is a statement of my knowledge of what the measurement result will be. For Bayesians, probabilities are **fundamentally related to our own knowledge about an event**. This means, for example, that in a Bayesian view, we can meaningfully talk about the probability that the true flux of a star lies in a given range. That probability codifies our knowledge of the value based on prior information and/or available data.\n",
    "\n",
    "In summary: \n",
    "\n",
    "- *Frequentist inference*: estimating an error on a parameter means: \"how much would the parameter change if I had other data\". \n",
    "- *Bayesian inference*: estimating an error on a parameter really means \"deriving a parameter and uncertainties on it\", something a frequentist cannot say as it strictly does not make sense (there is only one true value of a parameter that he tries to estimate and this does not make sense to speak of an uncertainty on a true value). For that purpose, Bayesian inference uses posterior distribution of the parameters (given the data) $p({\\boldsymbol{\\theta}} \\mid D)$. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. The Bayesian Problem Setting\n",
    "\n",
    "Thus the end-goal of a Bayesian analysis is a probabilistic statement about the universe.\n",
    "Roughly we want to measure\n",
    "\n",
    "$$\n",
    "P(science)\n",
    "$$\n",
    "\n",
    "Where \"science\" might be encapsulated in the cosmological model, the mass of a planet around a star, or whatever else we're interested in learning about.\n",
    "\n",
    "We don't of course measure this without reference to data, so more specifically we want to measure\n",
    "\n",
    "$$\n",
    "P(science~|~data)\n",
    "$$\n",
    "\n",
    "which should be read \"the probability of the science *given* the data.\"\n",
    "\n",
    "Of course, we should be explicit that this measurement is not done in a vaccum: generally before observing any data we have *some* degree of background information that informs the science, so we should actually write\n",
    "\n",
    "$$\n",
    "P(science~|~data, background\\ info)\n",
    "$$\n",
    "\n",
    "This should be read \"the probability of the science given the data *and* the background information\".\n",
    "\n",
    "Finally, there are often things in the scientific model that we don't particularly care about: these are known as \"nuisance parameters\". As an example of a nuisance parameter, if you are finding a planet in radial velocity data, the secular motion of the star is *extremely* important to model correctly, but in the end you don't really care about its best-fit value.\n",
    "\n",
    "With that in mind, we can write:\n",
    "\n",
    "$$\n",
    "P(science,nuisance\\ parameters~|~data, background\\ info)\n",
    "$$\n",
    "\n",
    "Where as before the comma should be read as an \"and\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, we write this down:\n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{\\theta}_S, \\boldsymbol{\\theta}_N~|~D, I)\n",
    "$$\n",
    "\n",
    "- $\\boldsymbol{\\theta}_S$ represents the \"science\": the set of parameters that we are interested in constraining\n",
    "- $\\boldsymbol{\\theta}_N$ represents the \"nuisance parameters\": the set of parameters that are important in the model, but are not particularly interesting for the scientific result.\n",
    "- $D$ represents the \"observed data\"\n",
    "- $I$ represents the information or knowledge you had before observing the data, including whatever made you choose the model you're fitting.\n",
    "\n",
    "Finally, we'll often just write $\\boldsymbol{\\theta} = (\\boldsymbol{\\theta}_S, \\boldsymbol{\\theta}_N)$ as a shorthand for all the model parameters.\n",
    "\n",
    "This quantity, $P(\\boldsymbol{\\theta}~|~D,I)$ is called the \"posterior probability\" and determining this quantity is the ultimate goal of a Bayesian analysis.\n",
    "\n",
    "Now all we need to do is compute it!\n",
    "\n",
    "The core problem is this: **We do not have a way to directly calculate** $P(\\boldsymbol{\\theta}~|~D,I)$. We often do have an expression for $P(D~|~\\boldsymbol{\\theta},I)$, but these two expressions are **not** equal.\n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{\\theta}~|~D,I) \\ne P(D~|~\\boldsymbol{\\theta},I)\n",
    "$$\n",
    "\n",
    "\n",
    "The way these two expressions are related is through the Bayes' theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III The Bayes' theorem / Bayes' Rule\n",
    "\n",
    "The definition of conditional probability is entirely symmetric, so we can write\n",
    "\n",
    "$$\n",
    "P(A \\cap B) = P(B \\cap A)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(A\\mid B)\\,P(B) = P(B\\mid A)\\,P(A)\n",
    "$$\n",
    "\n",
    "which is more commonly rearranged in this form:\n",
    "\n",
    "$$\n",
    "P(A\\mid B) = \\frac{P(B\\mid A)\\,P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "This is known as *Bayes' Theorem* or *Bayes' Rule*, and is important because it gives a formula for \"flipping\" conditional probabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we replace these labels (* This is were the devel of the controversy is hidden*), we find the usual expression of Bayes' theorem as it relates to model fitting:\n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{\\theta} \\mid D) = \\frac{P(D\\mid \\boldsymbol{\\theta})P(\\boldsymbol{\\theta})}{P(D)}\n",
    "$$\n",
    "\n",
    "Technically all the probabilities should all be conditioned on the information $I$:\n",
    "\n",
    "$$\n",
    "P(\\boldsymbol{\\theta} \\mid D,I) = \\frac{P(D \\mid \\boldsymbol{\\theta},I)P(\\boldsymbol{\\theta} \\mid I)}{P(D \\mid I)}\n",
    "$$\n",
    "\n",
    "Recall $\\boldsymbol{\\theta}$ is the model we're interested in, $D$ is the observed data, and $I$ encodes all the prior information, including what led us to choose the particular model we're using."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What is controversial in that expression ?* \n",
    "\n",
    "- We have a probability distribution over model parameters. A frequentist would say this is meaningless!\n",
    "\n",
    "- The answer depends on the prior $P(\\theta\\mid I)$. This is the probability of the model parameters without any data: how are we supposed to know that?\n",
    "\n",
    "Nevertheless, applying Bayes' rule in this manner gives us a means of quantifying our knowledge of the parameters $\\theta$ given observed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.1 Exploring the Terms in Bayesian Inference\n",
    "\n",
    "We have four terms in the above expression, and we need to make sure we understand them:\n",
    "\n",
    "#### $P(\\boldsymbol{\\theta}\\mid D, I)$ is the *posterior*.\n",
    "This is the quantity we want to compute: our knowledge of the model given the data & background knowledge (including the choice of model).\n",
    "\n",
    "#### $P(D\\mid\\boldsymbol{\\theta},I)$ is the *likelihood*.\n",
    "This measures the probability of seeing our data given the model. This is identical to the quantity maximized in frequentist *maximum-likelihood* approaches.\n",
    "\n",
    "#### $P(\\boldsymbol{\\theta}\\mid I)$ is the *prior*.\n",
    "This encodes any knowledge we had about the answer before measuring the current data.\n",
    "\n",
    "#### $P(D\\mid I)$ is the *Fully Marginalized Likelihood* (or *Evidence*)\n",
    "You might prefer the acronym *FML* (it's also called the *Evidence* - namely the evidence that the data D was generated by the model - among other things). Its complete expression is:\n",
    "\n",
    "$$\n",
    "P(D\\mid I) = \\int P(D\\mid\\boldsymbol{\\theta}, I) \\, P(\\boldsymbol{\\theta}) \\, \\rm{d}\\boldsymbol{\\theta}\n",
    "$$\n",
    "\n",
    "In the context of **model fitting**, it acts as a normalization constant and in most cases can be ignored. In **model selection**, the FML can become important (but it is costly to calculate as you need to evaluate the likelihood for all the values of your parameters $\\boldsymbol{\\theta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2 What is the Point?\n",
    "\n",
    "At first blush, this might all seem needlessly complicated. Why not simply maximize the likelihood and be done with it? Why multiply by a prior at all?\n",
    "\n",
    "- *Purity*: you quantify knowledge in terms of a probability, then follow the math to compute the answer. The fact that you need to specify a prior might be inconvenient, but we can't simply pretend it away.\n",
    "- *Parameter Uncertainties*: Whether frequentist or Bayesian, the maximum likelihood \"point estimate\" is only a small part of the picture. What we're really interested in scientifically is the uncertainty of the estimates. So simply reporting a point estimate is not appropriate. In frequentist approaches, \"error bars\" are generally computed from *Confidence Intervals*, which effectively measure the probability that the data encompass the true (fixed) value of the parameter, hence $P(\\hat{\\boldsymbol{\\theta}}\\mid\\boldsymbol{\\theta})$, rather than $P(\\boldsymbol{\\theta}\\mid D)$, which is effectively what we are interested in (and what is derived from the Bayesian approach). Note the difference: the Bayesian solution is a statement of probability about the parameter value given fixed bounds. The frequentist solution is a probability about the bounds given a fixed parameter value. This follows directly from the philosophical definitions of probability that the two approaches are based on.\n",
    "- *Marginalization and Nuisance Parameters*: Bayesian approaches offer a very natural way to systematically account for nuisance parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XX References:\n",
    "\n",
    "**Chapter 5 ** (5.1, 5.2, 5.3, 5.8) of the book <a class=\"anchor\" id=\"book\"></a> *Statistics, data mining and Machine learning in astronomy* by Z. Ivezic et al. in Princeton Series in Modern Astronomy. \n",
    "\n",
    "- This notebook includes a large fraction of the material that J. Vander Plas gave during the \"Bayesian Methods in Astronomy workshop\", presented at the 227th meeting of the American Astronomical Society. The full repository with that material can be found on GitHub: http://github.com/jakevdp/AAS227Workshop\n",
    "\n",
    "- More insights on the differences between frequentist and Bayesian approaches: see [J. VanderPlass blog posts](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/) \n",
    "\n",
    "- Jayes: [*Probability Theory: The Logic of Science*](http://bayes.wustl.edu/etj/prob/book.pdf).\n",
    "\n",
    "- For some approachable reading on frequentist vs. Bayesian uncertainties, I'd suggest [The Fallacy of Placing Confidence in Confidence Intervals](https://learnbayes.org/papers/confidenceIntervalsFallacy/), as well as Jake VanderPlast blog post on the topic, [Confidence, Credibility, and why Frequentism and Science do not Mix](http://jakevdp.github.io/blog/2014/06/12/frequentism-and-bayesianism-3-confidence-credibility/).\n",
    "\n",
    "- Foreman-Mackey et al. 2012 [*EMCEE, the MCMC hammer*](https://arxiv.org/abs/1202.3665) ; see also http://dan.iel.fm/emcee/current/\n",
    "\n",
    "- About the variety of approaches to MCMC: Allison and Dunkley 2013: [Comparison of sampling techniques for Bayesian parameter estimation](https://arxiv.org/abs/1308.2675). See also [How to Be a Bayesian in Python](http://jakevdp.github.io/blog/2014/06/14/frequentism-and-bayesianism-4-bayesian-in-python/). \n",
    "\n",
    "- Andreon 2011 [Understanding better (some) astronomical data using Bayesian methods](https://arxiv.org/abs/1112.3652)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
