{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to `scipy` and standard library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook provides an overview of the capabilities of the `scipy` module and of the standard library. It covers Sect. IV and V of [Modules_in__python.ipynb](Modules_in__python.ipynb). \n",
    "\n",
    "## Table of Content\n",
    "\n",
    "- [IV. Scipy](#IV)\n",
    "- [V. The standard library](#V) \n",
    "- [VI. References and supplementary material](#VI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. `scipy`  <a class=\"anchor\" id=\"IV\"></a>\n",
    "\n",
    "The scipy package contains various toolboxes dedicated to common issues in scientific computing. Its different submodules correspond to different applications, such as interpolation, integration, optimization, image processing, statistics, special functions, etc.\n",
    "\n",
    "`scipy` can be compared to other standard scientific-computing libraries, such as the GSL (GNU Scientific Library for C and C++), or Matlab’s toolboxes. scipy is the core package for scientific routines in Python; it is meant to operate efficiently on numpy arrays, so that numpy and scipy work hand in hand.\n",
    "\n",
    "Before implementing a routine, it is worth checking if the desired data processing is not already implemented in Scipy. As non-professional programmers, scientists often tend to re-invent the wheel, which leads to buggy, non-optimal, difficult-to-share and unmaintainable code. By contrast, Scipy‘s routines are optimized and tested, and should therefore be used when possible.\n",
    "\n",
    "We will NOT cover in details all the scipy capabilities/routines as this would be quite boring. We will briefly give an overview of some of them such that you know this exists ! We will also make use of several scipy functions in the future classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV.1 Overview  <a class=\"anchor\" id=\"IV.1\"></a>\n",
    "\n",
    "- *Special functions*: `scipy.special` \n",
    "Special functions are transcendental functions. Help is quite clearly written. Frequently used ones are:\n",
    "    * Bessel function, such as `scipy.special.jn()` (nth integer order Bessel function)\n",
    "    * Elliptic function (`scipy.special.ellipj()` for the Jacobian elliptic function, ...)\n",
    "    * Gamma function: `scipy.special.gamma()`, also note `scipy.special.gammaln()` which will give the log of Gamma to a higher numerical precision.\n",
    "    * Erf, the area under a Gaussian curve: `scipy.special.erf()`\n",
    "   \n",
    "- *Linear algebra operations*: `scipy.linalg`\n",
    "The scipy.linalg module provides standard linear algebra operations. This allows you to calculate the inverse (`scipy.linalg.inv()`), determinant (`scipy.linalg.det()`), of a square matrix. Note also that `numpy` also implements some operations on matrices (and beware: product of 2 numpy arrays is not a matrix product): \n",
    "    * `a.dot(b)` is the matrix product of a and b. If a, and b are 1-D vector than this is the scalar product (also called inner product) of the 2 vectors. \n",
    "    * `np.eye(2)` creates a diagonal matrix of 2x2 with 1 along the diagonal; \n",
    "    * `np.diag(a)` extracts the diagonal elements of matrix a. \n",
    "    * `np.cross(a,b)`: cross product of 2 vectors\n",
    "    * see http://www.python-course.eu/matrix_arithmetic.php for a didactic overview of matrix arithmetic with numpy. \n",
    "    \n",
    "- *Statistics and random numbers*: `scipy.stats`   \n",
    "The module `scipy.stats` contains statistical tools and probabilistic descriptions of random processes. We will use some of these tools in the next classes ! Note that random number generators for various random process can be found in `numpy.random`. *Beware* that there is also a package `random` that is a random variable generator, and it is **DIFFERENT** from `np.random` (some functions have the same name but do different things). For example, if you want to select k unique random elements from a population sequence, then use `random.sample()`, while `np.random.sample()` will return random floats in the half-open interval [0.0, 1.0[ ! . \n",
    "     \n",
    "- *Interpolation*: `scipy.interpolate`   \n",
    "The `scipy.interpolate` is useful for fitting a function from experimental data and thus evaluating points where no measure exists. The module is based on the [FITPACK Fortran subroutines](http://www.netlib.org/dierckx/index.html) from the [netlib](http://www.netlib.org/) project. You may consult [this page](https://scipy.github.io/old-wiki/pages/Cookbook/Interpolation.html) and [this page](http://scipy.github.io/old-wiki/pages/Cookbook/Matplotlib/Gridding_irregularly_spaced_data) for some nice examples of use of this function. \n",
    "    \n",
    "- *Pre-defined constants*: `scipy.constants`\n",
    "Contains most of the \"generic\" physical constants (c, h, G, ...). In addition there is also 2014 CODATA recommended values [CODATA2014](https://docs.scipy.org/doc/scipy/reference/constants.html#codata2014). To access those (as well as their units and uncertainties)  `import scipy.constants.physical_constants`. See help and/or consult the [scipy.constants doc](https://docs.scipy.org/doc/scipy/reference/constants.html#module-scipy.constants) to consult the list. To access e.g. the speed of light:\n",
    "``` python\n",
    "import scipy.constants \n",
    "scipy.constants.c\n",
    "    Out: 299792458.0\n",
    "scipy.constants.physical_constants[\"Planck mass\"]\n",
    "    Out: (2.17647e-08, 'kg', 5.1e-13)\n",
    "```\n",
    "    \n",
    "- *Routines for numerical integration*: `scipy.integrate()`\n",
    "The most generic integration routine (quadrature) is `scipy.integrate.quad()`. Other integration schemes exist such as fixed-order Gaussian quadrature (`fixed_quad()`), or Romberg integration method (`romberg`). `scipy.integrate` also features routines for integrating Ordinary Differential Equations (ODE). In particular, `scipy.integrate.odeint()` is a general-purpose integrator using LSODA (Livermore Solver for Ordinary Differential equations with Automatic method switching for stiff and non-stiff problems), see the [ODEPACK Fortran library](http://people.sc.fsu.edu/~jburkardt/f77_src/odepack/odepack.html) for more details. You can find a few examples in the [scipy lecture notes](http://www.scipy-lectures.org/intro/scipy.html#numerical-integration-scipy-integrate). \n",
    "   \n",
    "-  *File input/output*: `scipy.io` and `scipy.misc`\n",
    "This allows you to read some specific file formats generated by other programs such as MATLAB(R) (`scipy.io.loadmat`, `scipy.io.savemat`), idl (`scipy.io.idl`), or unformatted sequential files from Fortran code.   \n",
    "There is also a function to read images (`png`, with `scipy.misc`\n",
    "``` python \n",
    "from scipy import misc\n",
    "misc.imread('fname.png')    \n",
    "    Out: array(...)\n",
    "# Matplotlib also has a similar function\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imread('fname.png')    \n",
    "    Out: array(...)\n",
    "```\n",
    "\n",
    "Note: MATLAB(R) is a registered trademark of The MathWorks, Inc., 3 Apple Hill\n",
    "Drive, Natick, MA 01760-2098, USA.\n",
    "\n",
    "\n",
    "- *Fast Fourier Transforms*: `scipy.fftpack()`\n",
    "\n",
    "The `scipy.fftpack` module allows one to compute fast Fourier transforms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV.2 Function minimization and fitting: `scipy.optimize`    <a class=\"anchor\" id=\"IV.2\"></a>\n",
    "\n",
    "Optimization of a function is an important aspect of many data analysis problems. The `scipy.optimize` module provides useful algorithms for function minimization (scalar or multi-dimensional), curve fitting and root finding. \n",
    "\n",
    "We will focus here on one of the most used application of minimization techniques which is $\\chi^2$ minimization, namely curve fitting. As you know, curve fitting consists in minimizing the *weighted sum of the squared residuals* (i.e. residuals being the difference between the model and the data):    \n",
    "$\\chi^2 = \\sum_{i=1}^{N} \\left( \\frac{y_i - f(x_i)}{\\sigma_i} \\right)^2$\n",
    "\n",
    "While it is possible to define ourself a function that calculates the $\\chi^2$ of a given model and use some the functions implemented in `scipy.optimize` to solve this minimization problem, we can also directly use the convenience function `curve_fit()`, that already does it for us. This function implements the \"Levenberg-Marquardt\" algorithm to find the parameters that minimize your $\\chi^2$ merit function. Conceptually, that method switch between the \"Gradient Descent Method\" (you perturb the parameters by some amount \"h\" in the direction of steepest descent in your $\\chi^2$ function), and the \"Gauss-Newton Method\" that assumes that locally your function is quadratic in the parameters to determine \"h\", through a \"lagrange parameter\" lambda that is modified depending of the observed change in merit function. The `curve_fit()` function works like this:\n",
    "``` python\n",
    "# first create a function that defines your model\n",
    "# It must take the independent variable as the first argument and the parameters to fit as separate remaining arguments.\n",
    "def func(x, p1, p2, p3):\n",
    "y = f(x, p1, p2, p3)  # replace f(x, p1, p2, p3) by a function of vector x with parameters p1, p2, p3\n",
    "    return y\n",
    "# Second we call curve_fit(), first three arguments being func, xdata, ydata. Next two are optional initial guess and errors on y. \n",
    "pfit, pcov = scipy.optimize.curve_fit(func, xdata, ydata, p0=x0, sigma=sigma) \n",
    "# there is the possibility to constrain the parameters to certain ranges using method = 'trf'\n",
    "```\n",
    "We can move to the next cell to see in details an example of curve fitting. \n",
    "Beware, the covariance matrix, that allows you to make a proper (i.e. statistically valid) uncertainty estimate on the fitted parameters, does only make sense in case of gaussian noise. \n",
    "\n",
    "**Note**: If you are not too familiar with curve fitting/least square minimization, how to do when you have errors also on the independant variable (namely x), about difference between linear and non linear least-square (i.e. applied to linear and non linear models), about the basic concept behind the least square fitting algorithm ... I advise you to consult [Numerical recipes](http://www2.units.it/ipl/students_area/imm2/files/Numerical_Recipes.pdf) (Chapters 10, 15), and [Hogg, Bovy, Lang 2010](https://arxiv.org/abs/1008.4686). We can also have a dedicated lecture on this topic (*Let me know*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on what we have studied before, you should understand EVERY line of the following cells.\n",
    "# Import the scipy.optimize module that contains the function curve_fit()\n",
    "import scipy.optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Let's define a polynomial of order 2 as our model\n",
    "def polynomial(x, p1, p2, p3):\n",
    "    return p1 + p2*x + p3 * x**2\n",
    "\n",
    "# Create fake data: a line y = a + bx with a=0, b=0.3\n",
    "xdata = np.arange(0., 6., 0.05)\n",
    "ydata = 0.3 * xdata + 0.1 * np.random.randn(len(xdata))\n",
    "sigma = np.zeros(len(xdata)) + 0.1\n",
    "x0 = [0, 0, 0] # Define the initial parameters\n",
    "pfit, pcov = scipy.optimize.curve_fit(polynomial, xdata, ydata, x0, sigma)\n",
    "model = polynomial(xdata, pfit[0], pfit[1], pfit[2])\n",
    "# let's look to the most likely values of the parameters\n",
    "print ['p[ %i ] = %.2f' %(i, pfit[i]) for i in np.arange(3)]\n",
    "# Let's also print the errors on the parameters based on the covariance matrix\n",
    "print ['sigma[ %i ] = %.2f' %(i, np.sqrt(pcov[i, i])) for i in np.arange(3)]\n",
    "# We need to evaluate the chi^2 ourself\n",
    "chi2 = sum( ( (ydata - model ) / sigma )**2 )\n",
    "print 'chi^2 = %.3f and reduced chi^2 = %.3f' %(chi2, chi2 / ( len(xdata) - 3.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can visualize the results\n",
    "residuals = ydata-model  # Calculate the residuals\n",
    "# We create a window with 2 subplots\n",
    "f, ax = plt.subplots(nrows=2, ncols=1, sharex=True)\n",
    "# In the top one, we plot the data, the model, the \"true\" value\n",
    "ax[0].errorbar(xdata, ydata, yerr=sigma, ls='', marker='d', color='blue', label='data')\n",
    "ax[0].plot(xdata, model, color='red', label='model')\n",
    "ax[0].plot(xdata, 0.3 * xdata, lw=2,  ls='--', color='black', label='True')\n",
    "# We plot residuals in the bottom one, as well as an horizontal line\n",
    "ax[1].plot(xdata, residuals, 'o', color='red')\n",
    "ax[1].hlines(0, np.min(xdata), np.max(xdata))\n",
    "# We customize a bit more the plot\n",
    "ax[1].set_title('Residuals')\n",
    "ax[0].set_xlim(np.min(xdata)-0.1, np.max(xdata)+0.1)\n",
    "ax[0].legend(loc='best')\n",
    "ax[1].set_xlabel('x')\n",
    "ax[1].set_ylabel('data-model')\n",
    "ax[0].set_ylabel('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "# Are the residuals Normally distributed ?\n",
    "x = np.linspace(-1,1,100)\n",
    "hist_resi = plt.hist(residuals, bins=10, color='blue', alpha=0.2, normed=True)\n",
    "# Note in the above line that we have used the option \"normed = True\" . \n",
    "# Consequently, the integral of the histogram will sum to 1. This is effectively a pdf.\n",
    "fitpdf_mean, fitpdf_sigma = scipy.stats.norm.fit(residuals)\n",
    "print fitpdf_mean, fitpdf_sigma\n",
    "plt.plot(x, scipy.stats.norm.pdf(x, fitpdf_mean, fitpdf_sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**\n",
    "    \n",
    "We know that if we repeat the observations a large number of times, the $\\chi^2$ should get distributed following a $\\chi^2$ distribution. If $Q = \\sum_{i=1}^{N} z_i^2$ is the sum of the squared residuals, the $\\chi^2$ distribution, with $k = N$ degrees of freedom can be written:      \n",
    "$$\n",
    "p(Q/k) = \\frac{1} {(2\\,\\Gamma(k/2))}  (Q/2)^{k/2-1}  \\exp(-Q/2)\n",
    "$$\n",
    "\n",
    "- Write a short program that allows you to verify that if you repeat (the above) observations a sufficiently large number of times and carry out a least-square fit, your $\\chi^2$ effectively follows a $\\chi^2$ distribution. Note that the pdf associated to a $\\chi^2$ distribution is available in `scipy.stats.chi2.pdf()` (see the help for more info; the reference to \"df\" in the help corresponds to the number k of degrees of freedom). Tip: No need to fit anything ... you KNOW the # of dof !\n",
    "\n",
    "- If needed, adapt your program to change the number of dof (keep the model unchanged), and check how the chi^2 distribution looks like for dof = 1, dof = 3, dof=6. \n",
    "\n",
    "- Modify your program such that the errors provided to `curve_fit` are wrong (over estimated). How does this impact the $\\chi^2$ value and its distribution ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. The standard library  <a class=\"anchor\" id=\"V\"></a>\n",
    "   \n",
    "This section gives an overview of the very useful modules methods you may need to use at some point to manage your files, directory structures, platform-related file naming conventions, ... \n",
    "\n",
    "### `os`: operating system functionality\n",
    "\n",
    "> “A portable way of using operating system dependent functionality.”\n",
    "\n",
    "#### Directory and file manipulation:\n",
    "\n",
    "- Current directory:   `os.getcwd()`    \n",
    "\n",
    "- List a directory:  `os.listdir(os.curdir)`\n",
    "\n",
    "- Make a directory:   `os.mkdir('junkdir')`\n",
    "\n",
    "- Rename the directory:  `os.rename('junkdir', 'foodir')`\n",
    "\n",
    "- Delete a file:  `os.remove('junk.txt')`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Experiment with the use of OS and check-out the output\n",
    "print os.getcwd()\n",
    "print os.listdir(os.curdir)\n",
    "fp = open('junk.txt', 'w')    # first create an empty file\n",
    "fp.close()\n",
    "print 'junk.txt' in os.listdir(os.curdir)\n",
    "os.remove('junk.txt')\n",
    "print 'junk.txt' in os.listdir(os.curdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### os.path: path manipulations\n",
    "\n",
    "`os.path` provides common operations on pathnames:\n",
    "\n",
    "- Get the absolute path name for a file in a directory: `a = os.path.abspath('junk.txt')`  \n",
    "``` python\n",
    ">>> a\n",
    "    '/Users/cburns/src/scipy2009/scipy_2009_tutorial/source/junk.txt'\n",
    "```\n",
    "- Split Path name and file name:  `os.path.split(a)`   \n",
    "\n",
    "- Get the path part of `a`:  `os.path.dirname(a)`     \n",
    "\n",
    "- Filename part of `a`:  `os.path.basename(a)`    \n",
    "    'junk.txt'\n",
    "\n",
    "- Split file name into name and extension: `os.path.splitext(os.path.basename(a))`   \n",
    "\n",
    "- Check existence of a file in a path: `os.path.exists('junk.txt')`   \n",
    "\n",
    "- Check that a filename corresponds to a file: `os.path.isfile('junk.txt')`   \n",
    "\n",
    "- Check for a directory name: `os.path.isdir('junk.txt')`    \n",
    "\n",
    "- Pathname corresponding to home of the user: `os.path.expanduser('~')`     \n",
    "\n",
    "- Create a string by merging pathnames/strings: `os.path.join(os.path.expanduser('~'), 'local', 'bin')`    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `subprocess`: running an external command\n",
    "\n",
    "This is also very useful to call an externally compiled program.\n",
    "- Call a simple command, wait for it to finish, and get the return code:\n",
    "\n",
    "```  python\n",
    "import subprocess\n",
    "subprocess.call('chmod +x filename', shell=True)\n",
    "```\n",
    "\n",
    "- Communicate with the process (try for example with some_program.f):\n",
    "\n",
    "``` python\n",
    ">>> p1 = subprocess.Popen('./some_program',stdout=subprocess.PIPE)\n",
    ">>> p1.stdout.readline()\n",
    ">>> p1.send_signal(signal.SIGSTOP)\n",
    ">>> p1.send_signal(signal.SIGCONT)\n",
    ">>> p1.send_signal(signal.SIGKILL)\n",
    "```\n",
    "\n",
    "** Notes: **\n",
    "\n",
    "How to communicate with a program during execution:\n",
    "\n",
    "Suppose we want to run a program, and check its output while it’s running. For this, we need to read the program’s standard output while it is running, wait for the next line to appear, and end the loop when the output stream is closed. This can be done with:\n",
    "``` python \n",
    "def line_at_a_time(fileobj):\n",
    "    while True:\n",
    "        line = fileobj.readline()\n",
    "        if not line:\n",
    "            return\n",
    "        yield line\n",
    "```\n",
    "\n",
    "Now, we can run the program and check the output. Suppose “myprogram” prints ERROR to the screen when it encountered an error, and we want to kill the program whenever that occurs:\n",
    "``` python \n",
    ">>> p1 = subprocess.Popen('./my_program',stdout=subprocess.PIPE)\n",
    ">>> for line in line_at_a_time(p1.stdout):\n",
    "        if \"ERROR\" in line:\n",
    "            p1.send_signal(signal.SIGKILL)\n",
    "```\n",
    "Similarly, you can use subprocess.PIPE to send data to stdin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment variables:\n",
    "\n",
    "Get environment variable: \n",
    "\n",
    "- All defined environment variable:  `os.environ.keys()`   \n",
    "- Get the path to which corresponds a given env. variable:    \n",
    "`os.environ['PYTHONPATH']`     \n",
    "OR    \n",
    "`os.getenv('PYTHONPATH')`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sys`: system-specific information\n",
    "\n",
    "This is particularly useful if you want to make a quick fix to import some python codes located in a specific directory, or to figure out which python is used when you have multiple python installed on the machine ... (these kind of problems can now be more easily avoided if you install python via conda ...). \n",
    "\n",
    "System-specific information related to the Python interpreter.\n",
    "\n",
    "- Which version of python are you running and where is it installed: \n",
    "        * Platform: `sys.platform`\n",
    "        * Version of python: `sys.version`\n",
    "        * Location of python used: 'sys.prefix`\n",
    "\n",
    "- List of command line arguments passed to a Python script: `sys.argv`\n",
    "\n",
    "- The  list of strings that specifies the search path for modules is initialized from PYTHONPATH, and obtained from:   `sys.path` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. References and supplementary material: <a class=\"anchor\" id=\"VI\"></a>\n",
    "    \n",
    "- Standard python library:[http://www.ster.kuleuven.be/~pieterd/python/html/pure_python/standard_library.html](http://www.ster.kuleuven.be/~pieterd/python/html/pure_python/standard_library.html)\n",
    "\n",
    "- About minimization of functions and finding local/global minima with scipy (topic not covered in this lecture): http://www.scipy-lectures.org/advanced/mathematical_optimization/index.html\n",
    "\n",
    "- Scipy lecture notes: (from which part of numpy, scipy, matplotlib tutorial are inspired): [http://www.scipy-lectures.org/index.html](http://www.scipy-lectures.org/index.html)  (creative Commons 4.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
